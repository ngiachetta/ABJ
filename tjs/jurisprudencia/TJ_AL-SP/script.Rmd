---
title: "Inquérito Policial - São Paulo e Alagoas"
output: html_notebook
---

Objetivo: Obter os processos na segunda instância de classe "inquérito policial", nas Unidades Federativas de São Paulo e Alagoas.

```{r}
library(rvest)
library(esaj)
library(dplyr)
library(stringr)
library(httr)
```

# Caso 1: São Paulo

Em São Paulo, surgiram dois problemas:

    1) Parsear cjsg: Alguns documentos, cerca de 29 dos 52 baixados apresentavam erros ao parsear. Tentei parsear aqueles com erro, separadamente, porém o error persistiu.
    
    2) Ao dar continuidado ao código, mesmo com o erro no parser do cjsg, tive problemas para parsear cposg, no qual tive que remover `esaj:::parse_parts()` para que o código seguisse em frente.  

```{r}
# Obtendo a tabela com as classes do TJSP
classes_cjsg <- esaj::cjsg_table(type = "classes", tj = "tjsp")

# Filtrando inquérito policial
class_inq <- classes_cjsg %>% 
  filter(name0 == "PROCESSO CRIMINAL" & name1 == "Procedimentos Investigatórios" & str_detect(name5, "Inquérito"))

# Download dos processos de acordo com a classes desejada (Coleta: 16:26 dia 14 de Fevereiro)
esaj::download_cjsg(query = "",classes = class_inq$id5, 
                    path = "/home/nathang/Documentos/Scripts and Documents/ESTAGIO_ABJ/ABJ/tjs/jurisprudencia/TJ_AL-SP/data_raw_sp/cjsg_SP/", 
                    max_page = Inf, tj = "TJSP")

# Mensagem apresentada ao realizar o Download
## There are 52 pages to download
## This should take around 26.5 seconds

# Parseando os documentos baixados
files <- dir("/home/nathang/Documentos/Scripts and Documents/ESTAGIO_ABJ/ABJ/tjs/jurisprudencia/TJ_AL-SP/data_raw_sp/cjsg_SP/", full.names = TRUE, pattern = "page")
d_cjsg <- parse_cjsg(files)

# Consulta Processual (Coleta: 10:29)
processos <- unique(d_cjsg$id_lawsuit) %>%
  na.omit() # Foi preciso retirar NA para que a função download_cposg fosse executada

esaj::download_cposg(processos, "/home/nathang/Documentos/Scripts and Documents/ESTAGIO_ABJ/ABJ/tjs/jurisprudencia/TJ_AL-SP/data_raw_sp/cposg_SP")

files_cposg <- dir("/home/nathang/Documentos/Scripts and Documents/ESTAGIO_ABJ/ABJ/tjs/jurisprudencia/TJ_AL-SP/data_raw_sp/cposg_SP", full.names = TRUE)

# Parseando CPOSG
parser <- esaj::make_parser() %>% 
  esaj:::parse_data() %>% 
  #esaj:::parse_parts() %>% 
  esaj:::parse_movs() %>% 
  esaj:::parse_decisions()

d_cposg <- esaj::run_parser(file = files_cposg, parser = parser, 
                             path = "/home/nathang/Documentos/Scripts and Documents/ESTAGIO_ABJ/ABJ/tjs/jurisprudencia/TJ_AL-SP/data_raw_sp/cposg_rds_SP/")

rds_files <- dir("/home/nathang/Documentos/Scripts and Documents/ESTAGIO_ABJ/ABJ/tjs/jurisprudencia/TJ_AL-SP/data_raw_sp/cposg_rds_SP/", full.names = TRUE)
d_cposg <- purrr::map_dfr(rds_files, readRDS)

# Download das decisoes
acordaos <- d_cjsg$id_decision %>% 
  na.omit()
esaj::download_decision(acordaos, path = "/home/nathang/Documentos/Scripts and Documents/ESTAGIO_ABJ/ABJ/tjs/jurisprudencia/TJ_AL-SP/data_raw_sp/decision_SP")

readr::write_rds(d_cjsg, "/home/nathang/Documentos/Scripts and Documents/ESTAGIO_ABJ/ABJ/tjs/jurisprudencia/TJ_AL-SP/data_raw_sp/data_rds/d_cjsg.rds")

readr::write_rds(d_cposg, "/home/nathang/Documentos/Scripts and Documents/ESTAGIO_ABJ/ABJ/tjs/jurisprudencia/TJ_AL-SP/data_raw_sp/data_rds/d_cposg.rds")
```
Alguns documentos em São Paulo tiveram erros ao parsear. Sendo assim, trataremos destes casos manualmente.

```{r}
# Obtendo os caminhos dos arquivos que resultaram em error
files_error <- d_cjsg %>% 
  filter(result == "error") %>% 
  select(file) %>% 
  distinct() %>% 
  purrr::pluck(1)

files_error

m <- 1
node <- read_html(files_error[i], encoding = "UTF-8")

parse_SP <- function(node, m){
  id_lawsuit <- node %>% 
  rvest::html_nodes(xpath = '//*[@class="esajLinkLogin downloadEmenta"]') %>% html_text() %>% 
  str_trim() %>% tibble::tibble(id_lawsuit = .)

## id_decision
  id_decision <- node %>% 
    rvest::html_nodes(xpath = '//*[@class="esajLinkLogin downloadEmenta"]') %>%
    html_attr("cdacordao") %>% 
    str_trim() %>% tibble::tibble(id_decision = .)

  infos <- bind_cols(id_lawsuit, id_decision)

# id_page
## Precisa pegar apenas os elementos cujo os valores são impares
  ementaClass <- node %>% 
    rvest::html_nodes(xpath = '//*[@class="ementaClass"]') %>% 
    html_text()
  
  is_even <- function(x){
    result <- c()
    for (i in 1:length(x)){
      if(x[i] %% 2 == 1){
        result[i] <- TRUE
      } else {
        result[i] <- FALSE
      }
    }
    return(result)
  }
  
  id_page <- ementaClass[which(is_even(1:length(ementaClass)))] %>%
    str_replace_all("-", "") %>% 
    str_trim() %>% 
    tibble::tibble(id_page = .)

  # txt_summary
  txt_summary <- node %>%
    html_nodes(".mensagemSemFormatacao") %>%
    html_text() %>%
    tibble::tibble(txt_summary = .)

# class_subject
  class_base <- node %>% 
    html_nodes(xpath = '//*[@class="ementaClass2"]') %>%
    html_text() %>%
    stringr::str_split_fixed(':', 2) %>% 
    data.frame(stringsAsFactors = FALSE) %>%
    magrittr::set_names(c('key', 'val')) %>%
    dplyr::mutate_all(dplyr::funs(str_trim(.)))%>%
    dplyr::mutate(key = tolower(abjutils::rm_accent(key)),
                  key = stringr::str_replace_all(key, ' +', '_'),
                  key = stringr::str_replace_all(key, '[^a-z_]', ''),
                  key = stringr::str_replace_all(key, '_d[eo]_', '_')) %>% 
    mutate(ementa = case_when(str_detect(key, "[E-e]menta") == T ~ "S",
                            T~"N")) 
  i <- 1
  class_base$group <- NA
  for(l in 1:nrow(class_base)){
    if(class_base$ementa[l] == "N"){
      class_base$group[l] <- i
    } else{
      class_base$group[l] <- i
      i <- i + 1
    }
  }

  d_cjsg <- class_base %>% select(-ementa) %>% tidyr::spread("key", "val") %>%
    purrr::map_df(.,~str_trim(.x)) %>%
    dplyr::bind_cols(infos, id_page, txt_summary) %>% {
      if (!tibble::has_name(., "ementa"))
        dplyr::mutate(., ementa = NA_character_)
      else .} %>% 
    dplyr::select(id_page,
                  id_decision,
                  id_lawsuit,
                  class_subject = classeassunto,
                  district = comarca,
                court = orgao_julgador,
                dt_decision = data_julgamento,
                dt_publication = data_publicacao,
                #dt_registration = data_registro,
                rapporteur = relatora,
                summary = ementa,
                txt_summary)
  return(d_cjsg)
}
teste <- parse_SP(node, m)
```

# Caso 2: Alagoas

Como o pacote esaj não possui uma busca direta para o TJAL, optei por alterar primeiro a função `esaj::download_cjsg` para que recebesse os links de jurisprudência de Alagoas. Obs: A classe de inquérito policial é o mesmo para São Paulo e Alagoas, sendo assim, não precisei alterar o valor da classe

O código a seguir, portanto, faz os download das páginas html do tjal

```{r}
# Download 
path <- "/home/nathang/Documentos/Scripts and Documents/ESTAGIO_ABJ/ABJ/tjs/jurisprudencia/TJ_AL-SP/data-raw_al/cjsg_AL/"
query_post <- list(conversationId = "", 
                       dados.buscaInteiroTeor = "",
                       dados.pesquisarComSinonimos = "S",
                       contadoragente = 0, 
                       contadorMaioragente = 0, 
                       contadorjuizProlator = 0, 
                       contadorMaiorjuizProlator = 0, 
                       classesTreeSelection.values = class_inq$id5, #Classe inquerito
                       assuntosTreeSelection.values = "", 
                       contadorcomarca = 0,
                       contadorMaiorcomarca = 0,
                       secoesTreeSelection.values = "", 
                       dados.dtJulgamentoInicio = "", # Quinta mudança
                       dados.dtJulgamentoFim = "", 
                       dados.dtRegistroInicio = "", 
                       dados.dtRegistroFim = "", 
                       dados.origensSelecionadas = "T", 
                       tipoDecisaoSelecionados = "A", 
                       dados.ordenarPor = "dtPublicacao")
dir.create(path, FALSE, TRUE)
path <- normalizePath(path)
file <- stringr::str_c(path, "/search.html")
httr::POST("https://www2.tjal.jus.br/cjsg/resultadoCompleta.do", # Primeira mudança
  body = query_post, httr::config(ssl_verifypeer = FALSE), 
  httr::write_disk(file, TRUE))

page <- "1"
file <- stringr::str_c(path, "/page", page, ".html")

query_get <- list(tipoDeDecisao = "A", pagina = page, 
            conversationId = "")    
httr::GET("https://www2.tjal.jus.br/cjsg/trocaDePagina.do",  #Segunda mudança
                query = query_get, httr::config(ssl_verifypeer = FALSE), 
                httr::write_disk(file, TRUE))

files <- dir(path, full.names = TRUE, pattern = "page")
```

Como o parse do arquivo html volta error, vou parsear os dados manualmente. O código abaixo é uma adaptação do código encontrado em `esaj:::parse_cjsg_one()`, como por exemplo, removendo a data de registro (pois, eu não encontrei tal informação no html) e adicionando um controlador de fluxo para incluir os `id_pages` que solucionariam o problema encontrado no `tidyr::spread`.

```{r}
# Parseando o arquivo
node <- read_html(files, encoding = "UTF-8")

# infos
## id_lawsuit
id_lawsuit <- node %>% 
  rvest::html_nodes(xpath = '//*[@class="esajLinkLogin downloadEmenta"]') %>% html_text() %>% 
  str_trim() %>% tibble::tibble(id_lawsuit = .)

## id_decision
id_decision <- node %>% 
  rvest::html_nodes(xpath = '//*[@class="esajLinkLogin downloadEmenta"]') %>% html_attr("cdacordao") %>% 
  str_trim() %>% tibble::tibble(id_decision = .)

infos <- bind_cols(id_lawsuit, id_decision)

# id_page
## Precisa pegar apenas os elementos cujo os valores são impares
ementaClass <- node %>% 
  rvest::html_nodes(xpath = '//*[@class="ementaClass"]') %>% 
  html_text()
id_page <- ementaClass[c(1,3,5,7,9,11,13,15)] %>% str_replace_all("-", "") %>% str_trim() %>% 
   tibble::tibble(id_page = .)

# txt_summary
txt_summary <- node %>% html_nodes(".mensagemSemFormatacao") %>% html_text() %>% tibble::tibble(txt_summary = .)

# class_subject
class_base <- node %>% 
  html_nodes(xpath = '//*[@class="ementaClass2"]') %>%
  html_text() %>%
  stringr::str_split_fixed(':', 2) %>% 
  data.frame(stringsAsFactors = FALSE) %>%
  magrittr::set_names(c('key', 'val')) %>%
  dplyr::mutate_all(dplyr::funs(str_trim(.)))%>%
  dplyr::mutate(key = tolower(abjutils::rm_accent(key)),
                key = stringr::str_replace_all(key, ' +', '_'),
                key = stringr::str_replace_all(key, '[^a-z_]', ''),
                key = stringr::str_replace_all(key, '_d[eo]_', '_')) %>% 
  mutate(ementa = case_when(str_detect(key, "[E-e]menta") == T ~ "S",
                            T~"N")) 
i <- 1
class_base$group <- NA
for(l in 1:nrow(class_base)){
  if(class_base$ementa[l] == "N"){
    class_base$group[l] <- i
  } else{
    class_base$group[l] <- i
    i <- i + 1
  }
}

d_cjsg <- class_base %>% select(-ementa) %>% tidyr::spread("key", "val") %>% purrr::map_df(., ~str_trim(.x)) %>%
  dplyr::bind_cols(infos, id_page, txt_summary) %>% {
    if (!tibble::has_name(., "ementa"))
      dplyr::mutate(., ementa = NA_character_)
    else .} %>% 
  dplyr::select(id_page,
                id_decision,
                id_lawsuit,
                class_subject = classeassunto,
                district = comarca,
                court = orgao_julgador,
                dt_decision = data_julgamento,
                dt_publication = data_publicacao,
                #dt_registration = data_registro,
                rapporteur = relatora,
                summary = ementa,
                txt_summary)

# Consulta Processual (Coleta: 10:29)
processos <- unique(d_cjsg$id_lawsuit) %>%
  na.omit() # Foi preciso retirar NA para que a função download_cposg fosse executada

readr::write_rds(d_cjsg, "data-raw_al/data_rds/d_cjsg.rds")
```

Consulta processual

```{r}
processos <- stringr::str_replace_all(processos, "[[:punct:]]", "")
query <- processos[1]

path <- "/home/nathang/Documentos/Scripts and Documents/ESTAGIO_ABJ/ABJ/tjs/jurisprudencia/TJ_AL-SP/data-raw_al/"
session <- html_session("https://www2.tjal.jus.br/cposg5/open.do")
  
  # Preenchendo o formulário
  form <- session %>% 
    rvest::html_form() %>% 
    dplyr::first() %>% 
    rvest::set_values(.,`conversationId`="",
                      `cbPesquisa`="NUMPROC",
                      `tipoNuProcesso`="UNIFICADO",
                      `numeroDigitoAnoUnificado`= query,
                      `foroNumeroUnificado`="",
                      `uuidCaptcha`="")
    submit <- rvest::submit_form(session = session,
                               form = form)
  query <- stringr::str_replace_all(query, "[[:punct:]]", "") %>% 
    stringr::str_c(.,".html")
  dir.create(path, FALSE, TRUE)
  path <- normalizePath(path)
  file <- stringr::str_c(path, "\\")
  PathFile <- stringr::str_c(file, query)
  
  submit$url %>% httr::GET(httr::config(ssl_verifypeer = FALSE),write_disk(PathFile, overwrite = T)) #Verificar amanha
```

